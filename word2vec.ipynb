{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import word2vec\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/last_2_years_restaurant_reviews.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/riceball/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stop words\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toknizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = documents.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/riceball/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for doc in documents:\n",
    "    sentences.append(word_tokenize(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "stop_words = stopwords.words('english')\n",
    "for doc in sentences:\n",
    "    reviews.append([word for word in doc if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-93667957ce5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'reviews.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "out = open('reviews.pkl', 'wb')\n",
    "pickle.dump(reviews, out)\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-25 00:54:27,426 : INFO : collecting all words and their counts\n",
      "2019-04-25 00:54:27,428 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-04-25 00:54:27,555 : INFO : PROGRESS: at sentence #10000, processed 730974 words, keeping 28811 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-25 00:54:27,661 : INFO : PROGRESS: at sentence #20000, processed 1467341 words, keeping 41544 word types\n",
      "2019-04-25 00:54:27,775 : INFO : PROGRESS: at sentence #30000, processed 2179843 words, keeping 53025 word types\n",
      "2019-04-25 00:54:27,884 : INFO : PROGRESS: at sentence #40000, processed 2907112 words, keeping 62532 word types\n",
      "2019-04-25 00:54:27,984 : INFO : PROGRESS: at sentence #50000, processed 3570214 words, keeping 69838 word types\n",
      "2019-04-25 00:54:28,093 : INFO : PROGRESS: at sentence #60000, processed 4291466 words, keeping 77405 word types\n",
      "2019-04-25 00:54:28,199 : INFO : PROGRESS: at sentence #70000, processed 4990404 words, keeping 84236 word types\n",
      "2019-04-25 00:54:28,305 : INFO : PROGRESS: at sentence #80000, processed 5676441 words, keeping 90377 word types\n",
      "2019-04-25 00:54:28,428 : INFO : PROGRESS: at sentence #90000, processed 6433020 words, keeping 96895 word types\n",
      "2019-04-25 00:54:28,539 : INFO : PROGRESS: at sentence #100000, processed 7126446 words, keeping 102638 word types\n",
      "2019-04-25 00:54:28,703 : INFO : PROGRESS: at sentence #110000, processed 7823386 words, keeping 108516 word types\n",
      "2019-04-25 00:54:28,837 : INFO : PROGRESS: at sentence #120000, processed 8518643 words, keeping 113723 word types\n",
      "2019-04-25 00:54:28,943 : INFO : PROGRESS: at sentence #130000, processed 9188662 words, keeping 118800 word types\n",
      "2019-04-25 00:54:29,047 : INFO : PROGRESS: at sentence #140000, processed 9834195 words, keeping 123648 word types\n",
      "2019-04-25 00:54:29,160 : INFO : PROGRESS: at sentence #150000, processed 10537230 words, keeping 129012 word types\n",
      "2019-04-25 00:54:29,279 : INFO : PROGRESS: at sentence #160000, processed 11304849 words, keeping 134745 word types\n",
      "2019-04-25 00:54:29,400 : INFO : PROGRESS: at sentence #170000, processed 12093112 words, keeping 140342 word types\n",
      "2019-04-25 00:54:29,503 : INFO : PROGRESS: at sentence #180000, processed 12746736 words, keeping 144509 word types\n",
      "2019-04-25 00:54:29,670 : INFO : PROGRESS: at sentence #190000, processed 13443005 words, keeping 148970 word types\n",
      "2019-04-25 00:54:29,799 : INFO : PROGRESS: at sentence #200000, processed 14136946 words, keeping 153137 word types\n",
      "2019-04-25 00:54:29,912 : INFO : PROGRESS: at sentence #210000, processed 14849298 words, keeping 157511 word types\n",
      "2019-04-25 00:54:30,032 : INFO : PROGRESS: at sentence #220000, processed 15632265 words, keeping 162631 word types\n",
      "2019-04-25 00:54:30,146 : INFO : PROGRESS: at sentence #230000, processed 16363048 words, keeping 167107 word types\n",
      "2019-04-25 00:54:30,253 : INFO : PROGRESS: at sentence #240000, processed 17039154 words, keeping 171269 word types\n",
      "2019-04-25 00:54:30,368 : INFO : PROGRESS: at sentence #250000, processed 17736648 words, keeping 175318 word types\n",
      "2019-04-25 00:54:30,493 : INFO : PROGRESS: at sentence #260000, processed 18537665 words, keeping 180154 word types\n",
      "2019-04-25 00:54:30,598 : INFO : PROGRESS: at sentence #270000, processed 19197986 words, keeping 183906 word types\n",
      "2019-04-25 00:54:30,706 : INFO : PROGRESS: at sentence #280000, processed 19891122 words, keeping 187677 word types\n",
      "2019-04-25 00:54:30,836 : INFO : PROGRESS: at sentence #290000, processed 20727920 words, keeping 192259 word types\n",
      "2019-04-25 00:54:30,959 : INFO : PROGRESS: at sentence #300000, processed 21435729 words, keeping 196179 word types\n",
      "2019-04-25 00:54:31,067 : INFO : PROGRESS: at sentence #310000, processed 22115752 words, keeping 199991 word types\n",
      "2019-04-25 00:54:31,178 : INFO : PROGRESS: at sentence #320000, processed 22796024 words, keeping 203676 word types\n",
      "2019-04-25 00:54:31,284 : INFO : PROGRESS: at sentence #330000, processed 23459500 words, keeping 207094 word types\n",
      "2019-04-25 00:54:31,401 : INFO : PROGRESS: at sentence #340000, processed 24173911 words, keeping 211053 word types\n",
      "2019-04-25 00:54:31,516 : INFO : PROGRESS: at sentence #350000, processed 24893727 words, keeping 215225 word types\n",
      "2019-04-25 00:54:31,635 : INFO : PROGRESS: at sentence #360000, processed 25651986 words, keeping 219540 word types\n",
      "2019-04-25 00:54:31,750 : INFO : PROGRESS: at sentence #370000, processed 26375297 words, keeping 223255 word types\n",
      "2019-04-25 00:54:31,861 : INFO : PROGRESS: at sentence #380000, processed 27071515 words, keeping 226700 word types\n",
      "2019-04-25 00:54:31,977 : INFO : PROGRESS: at sentence #390000, processed 27792098 words, keeping 230687 word types\n",
      "2019-04-25 00:54:32,096 : INFO : PROGRESS: at sentence #400000, processed 28545080 words, keeping 234786 word types\n",
      "2019-04-25 00:54:32,218 : INFO : PROGRESS: at sentence #410000, processed 29318838 words, keeping 238771 word types\n",
      "2019-04-25 00:54:32,334 : INFO : PROGRESS: at sentence #420000, processed 30056067 words, keeping 242129 word types\n",
      "2019-04-25 00:54:32,467 : INFO : PROGRESS: at sentence #430000, processed 30737468 words, keeping 245342 word types\n",
      "2019-04-25 00:54:32,640 : INFO : PROGRESS: at sentence #440000, processed 31448483 words, keeping 248395 word types\n",
      "2019-04-25 00:54:32,765 : INFO : PROGRESS: at sentence #450000, processed 32202326 words, keeping 251699 word types\n",
      "2019-04-25 00:54:32,951 : INFO : PROGRESS: at sentence #460000, processed 32918361 words, keeping 255197 word types\n",
      "2019-04-25 00:54:33,073 : INFO : PROGRESS: at sentence #470000, processed 33609925 words, keeping 258088 word types\n",
      "2019-04-25 00:54:33,195 : INFO : PROGRESS: at sentence #480000, processed 34204578 words, keeping 260739 word types\n",
      "2019-04-25 00:54:33,365 : INFO : PROGRESS: at sentence #490000, processed 34921147 words, keeping 263834 word types\n",
      "2019-04-25 00:54:33,478 : INFO : PROGRESS: at sentence #500000, processed 35618409 words, keeping 267091 word types\n",
      "2019-04-25 00:54:33,589 : INFO : PROGRESS: at sentence #510000, processed 36278361 words, keeping 270054 word types\n",
      "2019-04-25 00:54:33,714 : INFO : PROGRESS: at sentence #520000, processed 37047281 words, keeping 273661 word types\n",
      "2019-04-25 00:54:33,830 : INFO : PROGRESS: at sentence #530000, processed 37768645 words, keeping 277045 word types\n",
      "2019-04-25 00:54:33,943 : INFO : PROGRESS: at sentence #540000, processed 38461164 words, keeping 280103 word types\n",
      "2019-04-25 00:54:34,054 : INFO : PROGRESS: at sentence #550000, processed 39157863 words, keeping 283299 word types\n",
      "2019-04-25 00:54:34,164 : INFO : PROGRESS: at sentence #560000, processed 39847674 words, keeping 286516 word types\n",
      "2019-04-25 00:54:34,286 : INFO : PROGRESS: at sentence #570000, processed 40582607 words, keeping 289843 word types\n",
      "2019-04-25 00:54:34,404 : INFO : PROGRESS: at sentence #580000, processed 41313097 words, keeping 293138 word types\n",
      "2019-04-25 00:54:34,516 : INFO : PROGRESS: at sentence #590000, processed 42008869 words, keeping 296199 word types\n",
      "2019-04-25 00:54:34,645 : INFO : PROGRESS: at sentence #600000, processed 42794129 words, keeping 299565 word types\n",
      "2019-04-25 00:54:34,768 : INFO : PROGRESS: at sentence #610000, processed 43520966 words, keeping 302585 word types\n",
      "2019-04-25 00:54:34,895 : INFO : PROGRESS: at sentence #620000, processed 44240569 words, keeping 305716 word types\n",
      "2019-04-25 00:54:35,007 : INFO : PROGRESS: at sentence #630000, processed 44934695 words, keeping 308657 word types\n",
      "2019-04-25 00:54:35,126 : INFO : PROGRESS: at sentence #640000, processed 45634305 words, keeping 311582 word types\n",
      "2019-04-25 00:54:35,134 : INFO : collected 311747 word types from a corpus of 45678207 raw words and 640718 sentences\n",
      "2019-04-25 00:54:35,134 : INFO : Loading a fresh vocabulary\n",
      "2019-04-25 00:54:35,260 : INFO : min_count=40 retains 21795 unique words (6% of original 311747, drops 289952)\n",
      "2019-04-25 00:54:35,260 : INFO : min_count=40 leaves 44754216 word corpus (97% of original 45678207, drops 923991)\n",
      "2019-04-25 00:54:35,337 : INFO : deleting the raw counts dictionary of 311747 items\n",
      "2019-04-25 00:54:35,345 : INFO : sample=0.001 downsamples 36 most-common words\n",
      "2019-04-25 00:54:35,346 : INFO : downsampling leaves estimated 35134415 word corpus (78.5% of prior 44754216)\n",
      "2019-04-25 00:54:35,440 : INFO : estimated required memory for 21795 words and 300 dimensions: 63205500 bytes\n",
      "2019-04-25 00:54:35,442 : INFO : resetting layer weights\n",
      "2019-04-25 00:54:35,679 : INFO : training model with 4 workers on 21795 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-25 00:54:36,694 : INFO : EPOCH 1 - PROGRESS: at 2.99% examples, 1073587 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:54:37,697 : INFO : EPOCH 1 - PROGRESS: at 6.07% examples, 1075773 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:54:38,703 : INFO : EPOCH 1 - PROGRESS: at 8.23% examples, 957773 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:54:39,705 : INFO : EPOCH 1 - PROGRESS: at 11.26% examples, 983373 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:54:40,708 : INFO : EPOCH 1 - PROGRESS: at 14.63% examples, 1022665 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:54:41,709 : INFO : EPOCH 1 - PROGRESS: at 18.04% examples, 1046977 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:54:42,713 : INFO : EPOCH 1 - PROGRESS: at 21.70% examples, 1068646 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:54:43,717 : INFO : EPOCH 1 - PROGRESS: at 24.98% examples, 1082800 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:54:44,717 : INFO : EPOCH 1 - PROGRESS: at 28.38% examples, 1095551 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:54:45,717 : INFO : EPOCH 1 - PROGRESS: at 31.79% examples, 1104083 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:54:46,724 : INFO : EPOCH 1 - PROGRESS: at 35.05% examples, 1112067 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:54:47,727 : INFO : EPOCH 1 - PROGRESS: at 38.54% examples, 1119094 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:54:48,727 : INFO : EPOCH 1 - PROGRESS: at 41.72% examples, 1121775 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:54:49,728 : INFO : EPOCH 1 - PROGRESS: at 44.98% examples, 1127663 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:54:50,730 : INFO : EPOCH 1 - PROGRESS: at 48.44% examples, 1131774 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:54:51,738 : INFO : EPOCH 1 - PROGRESS: at 52.01% examples, 1135452 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:54:52,741 : INFO : EPOCH 1 - PROGRESS: at 55.35% examples, 1137691 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:54:53,741 : INFO : EPOCH 1 - PROGRESS: at 58.32% examples, 1134659 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:54:54,756 : INFO : EPOCH 1 - PROGRESS: at 61.02% examples, 1123496 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:54:55,759 : INFO : EPOCH 1 - PROGRESS: at 63.52% examples, 1113400 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:54:56,759 : INFO : EPOCH 1 - PROGRESS: at 66.00% examples, 1104081 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:54:57,764 : INFO : EPOCH 1 - PROGRESS: at 68.71% examples, 1096144 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:54:58,769 : INFO : EPOCH 1 - PROGRESS: at 71.21% examples, 1087453 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:54:59,771 : INFO : EPOCH 1 - PROGRESS: at 73.93% examples, 1080517 words/s, in_qsize 8, out_qsize 0\n",
      "2019-04-25 00:55:00,775 : INFO : EPOCH 1 - PROGRESS: at 76.73% examples, 1074091 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:01,781 : INFO : EPOCH 1 - PROGRESS: at 79.56% examples, 1068625 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:02,784 : INFO : EPOCH 1 - PROGRESS: at 82.00% examples, 1062936 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:03,797 : INFO : EPOCH 1 - PROGRESS: at 84.78% examples, 1058104 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:04,806 : INFO : EPOCH 1 - PROGRESS: at 87.49% examples, 1053122 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:05,816 : INFO : EPOCH 1 - PROGRESS: at 90.06% examples, 1049219 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:06,817 : INFO : EPOCH 1 - PROGRESS: at 92.72% examples, 1045433 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:07,825 : INFO : EPOCH 1 - PROGRESS: at 95.24% examples, 1041724 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:08,832 : INFO : EPOCH 1 - PROGRESS: at 97.89% examples, 1037928 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:09,589 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-25 00:55:09,594 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-25 00:55:09,599 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-25 00:55:09,606 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-25 00:55:09,606 : INFO : EPOCH - 1 : training on 45678207 raw words (35132707 effective words) took 33.9s, 1035601 effective words/s\n",
      "2019-04-25 00:55:10,617 : INFO : EPOCH 2 - PROGRESS: at 2.42% examples, 879209 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:11,618 : INFO : EPOCH 2 - PROGRESS: at 5.11% examples, 904449 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:12,635 : INFO : EPOCH 2 - PROGRESS: at 7.84% examples, 912797 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:13,644 : INFO : EPOCH 2 - PROGRESS: at 10.51% examples, 913941 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:14,649 : INFO : EPOCH 2 - PROGRESS: at 13.13% examples, 916672 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:15,652 : INFO : EPOCH 2 - PROGRESS: at 15.79% examples, 919068 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:16,654 : INFO : EPOCH 2 - PROGRESS: at 18.52% examples, 920754 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:17,656 : INFO : EPOCH 2 - PROGRESS: at 21.36% examples, 922457 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:18,656 : INFO : EPOCH 2 - PROGRESS: at 23.99% examples, 923768 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:19,664 : INFO : EPOCH 2 - PROGRESS: at 26.49% examples, 924573 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:20,678 : INFO : EPOCH 2 - PROGRESS: at 29.34% examples, 925532 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:21,681 : INFO : EPOCH 2 - PROGRESS: at 31.95% examples, 923621 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:22,689 : INFO : EPOCH 2 - PROGRESS: at 34.51% examples, 924947 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:23,695 : INFO : EPOCH 2 - PROGRESS: at 37.16% examples, 923928 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:24,696 : INFO : EPOCH 2 - PROGRESS: at 39.73% examples, 924992 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:25,701 : INFO : EPOCH 2 - PROGRESS: at 42.50% examples, 925111 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:26,705 : INFO : EPOCH 2 - PROGRESS: at 44.89% examples, 924289 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:27,707 : INFO : EPOCH 2 - PROGRESS: at 47.38% examples, 921727 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:28,710 : INFO : EPOCH 2 - PROGRESS: at 50.15% examples, 922084 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:29,718 : INFO : EPOCH 2 - PROGRESS: at 52.79% examples, 920337 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:30,733 : INFO : EPOCH 2 - PROGRESS: at 55.41% examples, 920580 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:31,735 : INFO : EPOCH 2 - PROGRESS: at 57.92% examples, 920633 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:32,737 : INFO : EPOCH 2 - PROGRESS: at 60.64% examples, 921008 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:33,740 : INFO : EPOCH 2 - PROGRESS: at 63.15% examples, 921396 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:34,740 : INFO : EPOCH 2 - PROGRESS: at 65.62% examples, 921466 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:35,760 : INFO : EPOCH 2 - PROGRESS: at 68.30% examples, 920676 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:36,762 : INFO : EPOCH 2 - PROGRESS: at 70.47% examples, 915974 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:37,764 : INFO : EPOCH 2 - PROGRESS: at 73.14% examples, 916178 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:38,773 : INFO : EPOCH 2 - PROGRESS: at 76.07% examples, 916388 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:39,779 : INFO : EPOCH 2 - PROGRESS: at 78.50% examples, 913361 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:40,792 : INFO : EPOCH 2 - PROGRESS: at 81.07% examples, 912866 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:41,796 : INFO : EPOCH 2 - PROGRESS: at 83.70% examples, 913155 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:42,798 : INFO : EPOCH 2 - PROGRESS: at 86.38% examples, 913686 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:43,800 : INFO : EPOCH 2 - PROGRESS: at 89.01% examples, 913877 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:44,804 : INFO : EPOCH 2 - PROGRESS: at 91.72% examples, 914492 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-25 00:55:45,810 : INFO : EPOCH 2 - PROGRESS: at 94.18% examples, 914674 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:46,814 : INFO : EPOCH 2 - PROGRESS: at 96.78% examples, 915060 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:47,824 : INFO : EPOCH 2 - PROGRESS: at 99.49% examples, 915242 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:47,996 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-25 00:55:47,999 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-25 00:55:48,006 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-25 00:55:48,021 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-25 00:55:48,022 : INFO : EPOCH - 2 : training on 45678207 raw words (35136961 effective words) took 38.4s, 914906 effective words/s\n",
      "2019-04-25 00:55:49,030 : INFO : EPOCH 3 - PROGRESS: at 2.54% examples, 923173 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:50,032 : INFO : EPOCH 3 - PROGRESS: at 5.20% examples, 917894 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:51,046 : INFO : EPOCH 3 - PROGRESS: at 7.90% examples, 920143 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:52,049 : INFO : EPOCH 3 - PROGRESS: at 10.62% examples, 924475 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:53,054 : INFO : EPOCH 3 - PROGRESS: at 13.27% examples, 926586 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:54,066 : INFO : EPOCH 3 - PROGRESS: at 15.93% examples, 925933 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:55,081 : INFO : EPOCH 3 - PROGRESS: at 18.69% examples, 927181 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:56,085 : INFO : EPOCH 3 - PROGRESS: at 21.54% examples, 926841 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:57,099 : INFO : EPOCH 3 - PROGRESS: at 24.18% examples, 927030 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:58,100 : INFO : EPOCH 3 - PROGRESS: at 26.60% examples, 925886 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:55:59,115 : INFO : EPOCH 3 - PROGRESS: at 29.41% examples, 925265 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:00,124 : INFO : EPOCH 3 - PROGRESS: at 32.08% examples, 924783 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:01,125 : INFO : EPOCH 3 - PROGRESS: at 34.56% examples, 924243 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:02,139 : INFO : EPOCH 3 - PROGRESS: at 37.24% examples, 923218 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:03,140 : INFO : EPOCH 3 - PROGRESS: at 39.80% examples, 924343 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:04,143 : INFO : EPOCH 3 - PROGRESS: at 42.56% examples, 924626 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:05,159 : INFO : EPOCH 3 - PROGRESS: at 44.97% examples, 924121 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:06,160 : INFO : EPOCH 3 - PROGRESS: at 47.54% examples, 923289 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:07,176 : INFO : EPOCH 3 - PROGRESS: at 50.46% examples, 924511 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:08,179 : INFO : EPOCH 3 - PROGRESS: at 53.16% examples, 924448 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:09,180 : INFO : EPOCH 3 - PROGRESS: at 55.79% examples, 925004 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:10,181 : INFO : EPOCH 3 - PROGRESS: at 58.32% examples, 924919 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:11,186 : INFO : EPOCH 3 - PROGRESS: at 61.00% examples, 925028 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:12,186 : INFO : EPOCH 3 - PROGRESS: at 63.49% examples, 924990 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:13,188 : INFO : EPOCH 3 - PROGRESS: at 66.04% examples, 925499 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:14,189 : INFO : EPOCH 3 - PROGRESS: at 68.60% examples, 923715 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:15,197 : INFO : EPOCH 3 - PROGRESS: at 71.21% examples, 924053 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:16,200 : INFO : EPOCH 3 - PROGRESS: at 74.01% examples, 924449 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:17,205 : INFO : EPOCH 3 - PROGRESS: at 76.80% examples, 924531 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:18,210 : INFO : EPOCH 3 - PROGRESS: at 79.63% examples, 924789 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:19,219 : INFO : EPOCH 3 - PROGRESS: at 82.11% examples, 924540 words/s, in_qsize 8, out_qsize 1\n",
      "2019-04-25 00:56:20,221 : INFO : EPOCH 3 - PROGRESS: at 84.86% examples, 924993 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:21,225 : INFO : EPOCH 3 - PROGRESS: at 87.61% examples, 925285 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:22,230 : INFO : EPOCH 3 - PROGRESS: at 90.13% examples, 925329 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:23,232 : INFO : EPOCH 3 - PROGRESS: at 92.81% examples, 925468 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:24,236 : INFO : EPOCH 3 - PROGRESS: at 95.32% examples, 925615 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:25,241 : INFO : EPOCH 3 - PROGRESS: at 98.03% examples, 925823 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:25,941 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-25 00:56:25,944 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-25 00:56:25,964 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-25 00:56:25,968 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-25 00:56:25,969 : INFO : EPOCH - 3 : training on 45678207 raw words (35134368 effective words) took 37.9s, 925975 effective words/s\n",
      "2019-04-25 00:56:26,973 : INFO : EPOCH 4 - PROGRESS: at 2.50% examples, 910647 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:27,976 : INFO : EPOCH 4 - PROGRESS: at 5.22% examples, 922466 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:28,979 : INFO : EPOCH 4 - PROGRESS: at 7.90% examples, 924144 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:29,982 : INFO : EPOCH 4 - PROGRESS: at 10.60% examples, 925752 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:30,991 : INFO : EPOCH 4 - PROGRESS: at 13.25% examples, 926908 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:32,010 : INFO : EPOCH 4 - PROGRESS: at 15.96% examples, 927490 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:33,027 : INFO : EPOCH 4 - PROGRESS: at 18.71% examples, 928089 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:34,036 : INFO : EPOCH 4 - PROGRESS: at 21.60% examples, 928153 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:35,042 : INFO : EPOCH 4 - PROGRESS: at 24.23% examples, 929087 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:36,044 : INFO : EPOCH 4 - PROGRESS: at 26.65% examples, 927661 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:37,044 : INFO : EPOCH 4 - PROGRESS: at 29.45% examples, 928012 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:38,057 : INFO : EPOCH 4 - PROGRESS: at 32.14% examples, 927710 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:39,062 : INFO : EPOCH 4 - PROGRESS: at 34.66% examples, 927133 words/s, in_qsize 8, out_qsize 0\n",
      "2019-04-25 00:56:40,067 : INFO : EPOCH 4 - PROGRESS: at 37.36% examples, 927670 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:41,067 : INFO : EPOCH 4 - PROGRESS: at 39.92% examples, 927994 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:42,073 : INFO : EPOCH 4 - PROGRESS: at 42.66% examples, 927930 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:43,073 : INFO : EPOCH 4 - PROGRESS: at 45.05% examples, 928038 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:44,080 : INFO : EPOCH 4 - PROGRESS: at 47.72% examples, 927970 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:45,084 : INFO : EPOCH 4 - PROGRESS: at 50.55% examples, 927948 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:46,092 : INFO : EPOCH 4 - PROGRESS: at 53.23% examples, 927484 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:47,097 : INFO : EPOCH 4 - PROGRESS: at 55.87% examples, 927757 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:48,099 : INFO : EPOCH 4 - PROGRESS: at 58.44% examples, 927846 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:49,103 : INFO : EPOCH 4 - PROGRESS: at 61.11% examples, 927804 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:50,111 : INFO : EPOCH 4 - PROGRESS: at 63.59% examples, 927380 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-25 00:56:51,127 : INFO : EPOCH 4 - PROGRESS: at 66.15% examples, 927287 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:52,135 : INFO : EPOCH 4 - PROGRESS: at 68.82% examples, 926636 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:53,142 : INFO : EPOCH 4 - PROGRESS: at 71.40% examples, 926586 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:54,145 : INFO : EPOCH 4 - PROGRESS: at 74.31% examples, 926861 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:55,157 : INFO : EPOCH 4 - PROGRESS: at 77.01% examples, 926669 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:56,167 : INFO : EPOCH 4 - PROGRESS: at 79.80% examples, 926470 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:57,168 : INFO : EPOCH 4 - PROGRESS: at 82.31% examples, 926667 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:58,173 : INFO : EPOCH 4 - PROGRESS: at 85.03% examples, 926954 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:56:59,176 : INFO : EPOCH 4 - PROGRESS: at 87.81% examples, 927190 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:00,179 : INFO : EPOCH 4 - PROGRESS: at 90.35% examples, 927226 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:01,188 : INFO : EPOCH 4 - PROGRESS: at 93.02% examples, 927148 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:02,190 : INFO : EPOCH 4 - PROGRESS: at 95.51% examples, 927066 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:03,194 : INFO : EPOCH 4 - PROGRESS: at 98.07% examples, 926052 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:03,878 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-25 00:57:03,891 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-25 00:57:03,898 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-25 00:57:03,908 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-25 00:57:03,908 : INFO : EPOCH - 4 : training on 45678207 raw words (35132520 effective words) took 37.9s, 926128 effective words/s\n",
      "2019-04-25 00:57:04,926 : INFO : EPOCH 5 - PROGRESS: at 2.54% examples, 921812 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:05,937 : INFO : EPOCH 5 - PROGRESS: at 5.22% examples, 916834 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:06,941 : INFO : EPOCH 5 - PROGRESS: at 7.86% examples, 915113 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:07,944 : INFO : EPOCH 5 - PROGRESS: at 10.58% examples, 920800 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:08,945 : INFO : EPOCH 5 - PROGRESS: at 13.13% examples, 918147 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:09,950 : INFO : EPOCH 5 - PROGRESS: at 15.79% examples, 920012 words/s, in_qsize 8, out_qsize 0\n",
      "2019-04-25 00:57:10,953 : INFO : EPOCH 5 - PROGRESS: at 18.54% examples, 922488 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:11,957 : INFO : EPOCH 5 - PROGRESS: at 21.38% examples, 923768 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:12,974 : INFO : EPOCH 5 - PROGRESS: at 24.03% examples, 924016 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:13,976 : INFO : EPOCH 5 - PROGRESS: at 26.44% examples, 922305 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:14,981 : INFO : EPOCH 5 - PROGRESS: at 29.27% examples, 923550 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:15,995 : INFO : EPOCH 5 - PROGRESS: at 31.97% examples, 923497 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:16,996 : INFO : EPOCH 5 - PROGRESS: at 34.49% examples, 924144 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:18,004 : INFO : EPOCH 5 - PROGRESS: at 37.19% examples, 924072 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:19,025 : INFO : EPOCH 5 - PROGRESS: at 39.78% examples, 924408 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:20,030 : INFO : EPOCH 5 - PROGRESS: at 42.52% examples, 924093 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:21,031 : INFO : EPOCH 5 - PROGRESS: at 44.94% examples, 924432 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:22,034 : INFO : EPOCH 5 - PROGRESS: at 47.56% examples, 924776 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:23,041 : INFO : EPOCH 5 - PROGRESS: at 50.39% examples, 924702 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:24,045 : INFO : EPOCH 5 - PROGRESS: at 53.13% examples, 925370 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:25,060 : INFO : EPOCH 5 - PROGRESS: at 55.76% examples, 925303 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:26,078 : INFO : EPOCH 5 - PROGRESS: at 58.35% examples, 925195 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:27,079 : INFO : EPOCH 5 - PROGRESS: at 61.05% examples, 925769 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:28,084 : INFO : EPOCH 5 - PROGRESS: at 63.39% examples, 923287 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:29,084 : INFO : EPOCH 5 - PROGRESS: at 65.94% examples, 923918 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:30,091 : INFO : EPOCH 5 - PROGRESS: at 68.58% examples, 923193 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:31,095 : INFO : EPOCH 5 - PROGRESS: at 71.13% examples, 923103 words/s, in_qsize 8, out_qsize 1\n",
      "2019-04-25 00:57:32,097 : INFO : EPOCH 5 - PROGRESS: at 73.80% examples, 923032 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:33,103 : INFO : EPOCH 5 - PROGRESS: at 76.68% examples, 922862 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:34,109 : INFO : EPOCH 5 - PROGRESS: at 79.43% examples, 922408 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:35,119 : INFO : EPOCH 5 - PROGRESS: at 81.89% examples, 922216 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:36,125 : INFO : EPOCH 5 - PROGRESS: at 84.70% examples, 922853 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:37,136 : INFO : EPOCH 5 - PROGRESS: at 87.40% examples, 922774 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:38,139 : INFO : EPOCH 5 - PROGRESS: at 89.98% examples, 922918 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:39,140 : INFO : EPOCH 5 - PROGRESS: at 92.55% examples, 922748 words/s, in_qsize 8, out_qsize 0\n",
      "2019-04-25 00:57:40,145 : INFO : EPOCH 5 - PROGRESS: at 95.08% examples, 922702 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:41,147 : INFO : EPOCH 5 - PROGRESS: at 97.73% examples, 922894 words/s, in_qsize 7, out_qsize 0\n",
      "2019-04-25 00:57:41,961 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-04-25 00:57:41,964 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-04-25 00:57:41,982 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-04-25 00:57:41,988 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-04-25 00:57:41,988 : INFO : EPOCH - 5 : training on 45678207 raw words (35133386 effective words) took 38.1s, 922951 effective words/s\n",
      "2019-04-25 00:57:41,989 : INFO : training on a 228391035 raw words (175669942 effective words) took 186.3s, 942894 effective words/s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set values for various parameters\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 40   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "print(\"Training model...\")\n",
    "model = word2vec.Word2Vec(reviews, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-25 00:59:23,863 : INFO : precomputing L2-norms of word weight vectors\n",
      "2019-04-25 00:59:24,059 : INFO : saving Word2Vec object under word2vec, separately None\n",
      "2019-04-25 00:59:24,059 : INFO : not storing attribute vectors_norm\n",
      "2019-04-25 00:59:24,060 : INFO : not storing attribute cum_table\n",
      "2019-04-25 00:59:24,867 : INFO : saved word2vec\n"
     ]
    }
   ],
   "source": [
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# It can be helpful to create a meaningful model name and \n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model_name = \"word2vec\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-25 00:59:57,919 : INFO : loading Word2Vec object from word2vec\n",
      "2019-04-25 00:59:58,321 : INFO : loading wv recursively from word2vec.wv.* with mmap=None\n",
      "2019-04-25 00:59:58,321 : INFO : setting ignored attribute vectors_norm to None\n",
      "2019-04-25 00:59:58,322 : INFO : loading vocabulary recursively from word2vec.vocabulary.* with mmap=None\n",
      "2019-04-25 00:59:58,322 : INFO : loading trainables recursively from word2vec.trainables.* with mmap=None\n",
      "2019-04-25 00:59:58,323 : INFO : setting ignored attribute cum_table to None\n",
      "2019-04-25 00:59:58,323 : INFO : loaded word2vec\n"
     ]
    }
   ],
   "source": [
    "model = word2vec.Word2Vec.load(\"word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
